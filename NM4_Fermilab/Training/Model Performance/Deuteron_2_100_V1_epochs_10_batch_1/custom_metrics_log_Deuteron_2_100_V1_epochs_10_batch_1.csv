Epoch,Learning Rate,Training Loss,Validation Loss,Loss Difference
1,9.999999747378752e-05,0.24771437048912048,0.24625204503536224,0.0014623254537582397
2,9.999999747378752e-05,0.24543942511081696,0.24580737948417664,-0.0003679543733596802
3,9.999999747378752e-05,0.24545003473758698,0.24611221253871918,-0.0006621778011322021
4,9.999999747378752e-05,0.24546228349208832,0.24575422704219818,-0.0002919435501098633
5,9.999999747378752e-05,0.24545074999332428,0.2456960380077362,-0.00024528801441192627
6,9.999999747378752e-05,0.2454177439212799,0.2460678517818451,-0.0006501078605651855
7,9.999999747378752e-05,0.245432510972023,0.24576596915721893,-0.00033345818519592285
8,9.999999747378752e-05,0.2454247772693634,0.24594369530677795,-0.0005189180374145508
9,9.999999747378752e-05,0.24544233083724976,0.2457304149866104,-0.00028808414936065674
10,9.999999747378752e-05,0.24543648958206177,0.2457469254732132,-0.0003104358911514282
