Epoch,Learning Rate,Training Loss,Validation Loss,Loss Difference
1,9.999999747378752e-05,0.24774561822414398,0.24574196338653564,0.0020036548376083374
2,9.999999747378752e-05,0.2454393208026886,0.2459147721529007,-0.00047545135021209717
3,9.999999747378752e-05,0.24544937908649445,0.2457805871963501,-0.00033120810985565186
4,9.999999747378752e-05,0.24543945491313934,0.24590662121772766,-0.00046716630458831787
5,9.999999747378752e-05,0.24542813003063202,0.2457474321126938,-0.0003193020820617676
6,9.999999747378752e-05,0.24540431797504425,0.2457738220691681,-0.00036950409412384033
7,9.999999747378752e-05,0.24541975557804108,0.24596035480499268,-0.0005405992269515991
8,9.999999747378752e-05,0.24542874097824097,0.2458854466676712,-0.0004567056894302368
9,9.999999747378752e-05,0.2454194724559784,0.24566103518009186,-0.00024156272411346436
10,9.999999747378752e-05,0.24541381001472473,0.24568991363048553,-0.0002761036157608032
11,9.999999747378752e-05,0.24540767073631287,0.24575133621692657,-0.0003436654806137085
12,9.999999747378752e-05,0.2454085350036621,0.2457844465970993,-0.0003759115934371948
13,9.999999747378752e-05,0.2454441338777542,0.2458673119544983,-0.0004231780767440796
14,9.999999747378752e-05,0.24539858102798462,0.24595153331756592,-0.0005529522895812988
15,9.999999747378752e-05,0.24539746344089508,0.2456580251455307,-0.0002605617046356201
